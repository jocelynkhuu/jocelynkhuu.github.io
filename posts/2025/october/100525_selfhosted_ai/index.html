<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="">
<meta name="description" content="Using Ollama and Open WebUI to self-host your own LLMs" />
<meta name="keywords" content=", AI, ML, LLM, thoughts, post, blog" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://khuuj.com/posts/2025/october/100525_selfhosted_ai/" />


    <title>
        
            Ollama &#43; Open WebUI :: Jocelyn&#39;s mind wanderings 
        
    </title>





  <link rel="stylesheet" href="https://khuuj.com/main.min.ab5336003ba331300318b49292c672210905baf1ef5410a739f647e70c8808fa.css" integrity="sha256-q1M2ADujMTADGLSSksZyIQkFuvHvVBCnOfZH5wyICPo=" crossorigin="anonymous">





    <link rel="apple-touch-icon" sizes="180x180" href="https://khuuj.com/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://khuuj.com/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://khuuj.com/favicon-16x16.png">
    <link rel="manifest" href="https://khuuj.com/site.webmanifest">
    <link rel="mask-icon" href="https://khuuj.com/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://khuuj.com/favicon.ico">
    <meta name="msapplication-TileColor" content="">



  <meta itemprop="name" content="Ollama &#43; Open WebUI">
  <meta itemprop="description" content="Using Ollama and Open WebUI to self-host your own LLMs">
  <meta itemprop="datePublished" content="2025-10-05T01:05:58-07:00">
  <meta itemprop="dateModified" content="2025-10-05T01:05:58-07:00">
  <meta itemprop="wordCount" content="1245">
  <meta itemprop="image" content="https://khuuj.com/">
  <meta itemprop="keywords" content="AI,ML,LLM,Thoughts,Post,Blog">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://khuuj.com/">
  <meta name="twitter:title" content="Ollama &#43; Open WebUI">
  <meta name="twitter:description" content="Using Ollama and Open WebUI to self-host your own LLMs">



    <meta property="og:url" content="https://khuuj.com/posts/2025/october/100525_selfhosted_ai/">
  <meta property="og:site_name" content="Jocelyn&#39;s mind wanderings">
  <meta property="og:title" content="Ollama &#43; Open WebUI">
  <meta property="og:description" content="Using Ollama and Open WebUI to self-host your own LLMs">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-10-05T01:05:58-07:00">
    <meta property="article:modified_time" content="2025-10-05T01:05:58-07:00">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="ML">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="Thoughts">
    <meta property="article:tag" content="Post">
    <meta property="article:tag" content="Blog">
    <meta property="og:image" content="https://khuuj.com/">






    <meta property="article:published_time" content="2025-10-05 01:05:58 -0700 PDT" />












    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://khuuj.com/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                cd ~</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://khuuj.com/about">whoami</a></li><li><a href="https://khuuj.com/posts">posts</a></li><li><a href="https://khuuj.com/resume">resume</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
                <span class="theme-toggle not-selectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
   <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
   3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
   13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
 </svg></span>
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        6 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://khuuj.com/posts/2025/october/100525_selfhosted_ai/">Ollama + Open WebUI</a>
      </h1>

      
        <div class="post-excerpt">Using Ollama and Open WebUI to self-host your own LLMs</div>
      

      

      

      <div class="post-content">
        <h1 id="what-exactly-is-ai">What exactly is AI?</h1>
<p><em>Note: I will primary be using ChatGPT to define a lot of what this is</em></p>
<p>AI has taken off quickly within the last couple of years and even people like my aunt are using it in their everyday lives to help with tasks like learning, searching, and even translating.</p>
<p>AI = Artificial Intelligence</p>
<p><strong>From ChatGPT:</strong></p>
<blockquote>
<p>AI refers to any system or machine that can perform tasks that normally require human intelligence — like understanding language, recognizing images, solving problems, or making decisions.</p>
<p>Examples:</p>
<ul>
<li>A chatbot that can answer questions</li>
<li>A self-driving car that detects pedestrians</li>
<li>A spam filter that learns to block unwanted emails</li>
</ul></blockquote>
<p>You may also hear the term &ldquo;ML&rdquo; for Machine Learning which is a subset of AI and how most AI learn.</p>
<blockquote>
<p>Instead of being explicitly programmed with rules, ML models learn from data.
They look for patterns and improve automatically as they see more examples.</p>
<p>Example:</p>
<ul>
<li>If you feed a model thousands of cat and dog photos labeled correctly, it learns to recognize cats vs dogs without you hard-coding “cats have whiskers.”</li>
</ul></blockquote>
<p>Then there&rsquo;s &ldquo;DL&rdquo; for Deep Learning which is a subset of ML.</p>
<blockquote>
<p>Deep Learning is a subset of Machine Learning that uses artificial neural networks — lots of layers (“deep”) that learn patterns from raw data.</p>
<p>Instead of humans deciding which features to look for, the network figures them out automatically.
One of the most classic deep learning examples is a Convolutional Neural Network (CNN) that identifies what’s in an image.</p>
<p>For example:</p>
<ul>
<li>You feed in a picture of a cat 🐱</li>
<li>The network’s early layers detect edges</li>
<li>Middle layers detect shapes (ears, eyes, whiskers)</li>
<li>Deep layers detect whole objects (cat)</li>
<li>Output: “Cat” (with 99.7% confidence)</li>
<li>That’s all done automatically — no human manually coding “cat = whiskers + tail + ears.”</li>
</ul></blockquote>
<p>Then there are &ldquo;LLMs&rdquo; or Large Language Models</p>
<blockquote>
<p>LLMs are a specific type of ML model, trained on massive amounts of text to understand and generate human language.</p>
<p>They’re built using deep learning (a subset of ML) — particularly neural networks with billions of parameters.
They predict the next word in a sequence, which allows them to write, summarize, translate, and even reason.</p>
<p>Examples:</p>
<ul>
<li>GPT-5</li>
<li>Claude, Gemini, Mistral, Llama</li>
</ul></blockquote>
<p>So the hierarchy is something like</p>
<pre tabindex="0"><code>Artificial Intelligence
└── Machine Learning
    └── Deep Learning
        └── Large Language Models
</code></pre><h3 id="what-is-gpt">What is GPT?</h3>
<p>GPT = Generative Pre-trained Transformer (A type of LLM)</p>
<ul>
<li>“Generative” means the model creates new content, rather than just classifying or retrieving information.</li>
<li>“pre-trained” means it already has general language knowledge before you use it.</li>
<li>&ldquo;Transformer is the architecture — the actual neural network design that makes GPT work. It uses a mechanism called self-attention which means the model looks at all words in a sentence at once and learns which ones are most relevant to each other.</li>
</ul>
<h3 id="what-are-tokens-and-parameters">What are tokens and parameters?</h3>
<p>Every answer you get from an LLM is built by predicting one token at a time, incredibly fast — millions of times per second.</p>
<ul>
<li>Tokens: what the model reads and writes
<ul>
<li>Tokens are small chunks of text — not quite words, not quite letters.They’re how the model “sees” language.</li>
</ul>
</li>
<li>Parameters: what the model learns (its “knowledge”)
<ul>
<li>Parameters are the learned weights inside the neural network. They’re the numbers that determine how the model connects and transforms one token to the next.</li>
</ul>
</li>
</ul>
<p>Now that we have a basic understanding of what AI is, how can we set it up and use it?</p>
<h3 id="how-do-we-use-ai">How do we use AI?</h3>
<p>One of the most obvious ways of using AI is simply going to a website like chatgpt.com and using it like a chatbot. You can ask questions and it can provide answers.</p>
<p>One of the key concerns of this is of course privacy and security. Everything that you type and paste into the model can be used to train it or the company behind the LLM can also have access to every single chat log. Companies have had to crack down on AI use as people have pasted confidential or sensitive information into it.</p>
<h2 id="self-hosting-your-llms">Self hosting your LLMs</h2>
<p>There are open source LLMs that can be downloaded and self-hosted locally on your computer. This is where <a href="https://ollama.com">Ollama</a> comes in.</p>
<blockquote>
<p>Ollama is a tool and runtime for running Large Language Models (LLMs) locally on your computer — instead of in the cloud (like ChatGPT does). It lets you download and run open-source LLMs right on your own device (Mac, Windows, or Linux).</p>
<p>Ollama handles all the hard parts of working with LLMs:</p>
<ul>
<li>Downloading models (like Llama 3, Mistral, Phi-3, Gemma, etc.)</li>
<li>Running them efficiently on your CPU or GPU</li>
<li>Managing prompts, context, and chat history</li>
<li>Exposing a simple API (like OpenAI’s) for developers to use in scripts or apps</li>
</ul>
<p>So you can use it both:</p>
<ul>
<li>From the command line (chat directly)</li>
<li>Or in your own programs (like a local AI API)</li>
</ul></blockquote>
<h2 id="setting-up-ollama--openwebui">Setting up Ollama + OpenWebUI</h2>
<ol>
<li>Download <a href="https://ollama.com">Ollama</a></li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>❯ ollama
</span></span><span style="display:flex;"><span>Usage:
</span></span><span style="display:flex;"><span>  ollama <span style="color:#f92672">[</span>flags<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  ollama <span style="color:#f92672">[</span>command<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Available Commands:
</span></span><span style="display:flex;"><span>  serve       Start ollama
</span></span><span style="display:flex;"><span>  create      Create a model
</span></span><span style="display:flex;"><span>  show        Show information <span style="color:#66d9ef">for</span> a model
</span></span><span style="display:flex;"><span>  run         Run a model
</span></span><span style="display:flex;"><span>  stop        Stop a running model
</span></span><span style="display:flex;"><span>  pull        Pull a model from a registry
</span></span><span style="display:flex;"><span>  push        Push a model to a registry
</span></span><span style="display:flex;"><span>  signin      Sign in to ollama.com
</span></span><span style="display:flex;"><span>  signout     Sign out from ollama.com
</span></span><span style="display:flex;"><span>  list        List models
</span></span><span style="display:flex;"><span>  ps          List running models
</span></span><span style="display:flex;"><span>  cp          Copy a model
</span></span><span style="display:flex;"><span>  rm          Remove a model
</span></span><span style="display:flex;"><span>  help        Help about any command
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Flags:
</span></span><span style="display:flex;"><span>  -h, --help      help <span style="color:#66d9ef">for</span> ollama
</span></span><span style="display:flex;"><span>  -v, --version   Show version information
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Use <span style="color:#e6db74">&#34;ollama [command] --help&#34;</span> <span style="color:#66d9ef">for</span> more information about a command.
</span></span></code></pre></div><ol start="2">
<li>Download models</li>
</ol>
<p><em>Note: be aware of your hardware limitations. The more parameters there are the more resources it needs from your computer.</em></p>
<p><em>From Ollama&rsquo;s own <a href="https://github.com/ollama/ollama">documentation</a>: You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.</em></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>❯ ollama run qwen3
</span></span><span style="display:flex;"><span>pulling manifest
</span></span><span style="display:flex;"><span>pulling a3de86cd1c13: 100% ▕███████████████████████████████▏ 5.2 GB
</span></span><span style="display:flex;"><span>pulling ae370d884f10: 100% ▕███████████████████████████████▏ 1.7 KB
</span></span><span style="display:flex;"><span>pulling d18a5cc71b84: 100% ▕███████████████████████████████▏  <span style="color:#ae81ff">11</span> KB
</span></span><span style="display:flex;"><span>pulling cff3f395ef37: 100% ▕███████████████████████████████▏  <span style="color:#ae81ff">120</span> B
</span></span><span style="display:flex;"><span>pulling 05a61d37b084: 100% ▕███████████████████████████████▏  <span style="color:#ae81ff">487</span> B
</span></span><span style="display:flex;"><span>verifying sha256 digest
</span></span><span style="display:flex;"><span>writing manifest
</span></span><span style="display:flex;"><span>success
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Send a message <span style="color:#f92672">(</span>/? <span style="color:#66d9ef">for</span> help<span style="color:#f92672">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>❯ ollama list
</span></span><span style="display:flex;"><span>NAME            ID              SIZE      MODIFIED
</span></span><span style="display:flex;"><span>qwen3:latest    500a1f067a9f    5.2 GB    <span style="color:#ae81ff">58</span> seconds ago
</span></span><span style="display:flex;"><span>gemma3:4b       a2af6cc3eb7f    3.3 GB    <span style="color:#ae81ff">2</span> hours ago
</span></span><span style="display:flex;"><span>llama3:8b       365c0bd3c000    4.7 GB    <span style="color:#ae81ff">2</span> hours ago
</span></span></code></pre></div><ol start="3">
<li>Use your models directly in the cmd line</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>❯ ollama run gemma3:4b
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; hello
</span></span><span style="display:flex;"><span>Hello there! How’s your day going so far? Is there anything I can help you with today? 😊
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Do you want to:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>*   Chat about something?
</span></span><span style="display:flex;"><span>*   Ask me a question?
</span></span><span style="display:flex;"><span>*   Play a game?
</span></span><span style="display:flex;"><span>*   Just say hello back?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; /bye
</span></span></code></pre></div><h2 id="build-a-webui-to-interact-with-the-llms">Build a webUI to interact with the LLMs</h2>
<p>There is an open source project called <a href="https://github.com/open-webui/open-webui">Open WebUI</a> to help us build an interface similar to ChatGPT. It is very easy to set up especially with a container.</p>
<p>Here is what I did to run it in a container through podman:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>❯ podman run -d -p 3000:8080 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -v open-webui:/app/backend/data <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name open-webui <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --restart<span style="color:#f92672">=</span>always <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  ghcr.io/open-webui/open-webui:main
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>8ceae59c06c485d86122fdb687f9f2e80708b4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>❯ podman ps -a
</span></span><span style="display:flex;"><span>CONTAINER ID  IMAGE                               COMMAND        CREATED        STATUS                     PORTS                   NAMES
</span></span><span style="display:flex;"><span>8ceae59c06c4  ghcr.io/open-webui/open-webui:main  bash start.sh  <span style="color:#ae81ff">4</span> seconds ago  Up <span style="color:#ae81ff">4</span> seconds <span style="color:#f92672">(</span>starting<span style="color:#f92672">)</span>    0.0.0.0:3000-&gt;8080/tcp  open-webui
</span></span></code></pre></div><p>Now I can go to http://localhost:3000 to access the web UI. There will be a dropdown to select which model to use.</p>
<p><img src="https://khuuj.com/static/openwebui.png" alt="openwebui"></p>
<p>Now everything here is self-hosted so the data is safely stored on our local host.</p>
<h2 id="how-about-using-it-in-vscode">How about using it in VSCode?</h2>
<p>There is a VSCode extension called <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">Continue</a></p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://khuuj.com/tags/ai/">AI</a></span>
        <span class="tag"><a href="https://khuuj.com/tags/ml/">ML</a></span>
        <span class="tag"><a href="https://khuuj.com/tags/llm/">LLM</a></span>
        <span class="tag"><a href="https://khuuj.com/tags/thoughts/">thoughts</a></span>
        <span class="tag"><a href="https://khuuj.com/tags/post/">post</a></span>
        <span class="tag"><a href="https://khuuj.com/tags/blog/">blog</a></span>
        
    </p>

      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        1245 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2025-10-05 01:05
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        
        <div class="pagination__title">
            <span class="pagination__title-h">Read other posts</span>
            <hr />
        </div>
        

        <div class="pagination__buttons">
            

            
            <span class="button next">
                <a href="https://khuuj.com/posts/2025/august/080625_dd/">
                    <span class="button__text">Updating the BIOS on an older Lenovo Thinkpad - Linux Edition</span>
                    <span class="button__icon">→</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://khuuj.com/bundle.min.ad54ad97364f77ede35def9096b162bb1f0b3973aa50b080f5e82fa147f6882e2a7200d7535adbf9b51bebf939f1c1ca9bbe6be87530092aca720eac4a226fda.js" integrity="sha512-rVStlzZPd&#43;3jXe&#43;QlrFiux8LOXOqULCA9egvoUf2iC4qcgDXU1rb&#43;bUb6/k58cHKm75r6HUwCSrKcg6sSiJv2g=="></script>




    </body>
</html>
